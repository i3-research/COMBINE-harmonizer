{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3445cbb4-43fa-4cd3-9c19-2db96cf33c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:37:43.398924Z",
     "iopub.status.busy": "2025-05-05T19:37:43.398568Z",
     "iopub.status.idle": "2025-05-05T19:37:44.491698Z",
     "shell.execute_reply": "2025-05-05T19:37:44.491372Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.copy_on_write = True\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "import os\n",
    "\n",
    "import re\n",
    "import time\n",
    "\n",
    "import itertools\n",
    "\n",
    "import COMBINE_harmonizer\n",
    "from COMBINE_harmonizer import cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e67149",
   "metadata": {},
   "source": [
    "## 01. init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244f3e24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:37:44.493356Z",
     "iopub.status.busy": "2025-05-05T19:37:44.493213Z",
     "iopub.status.idle": "2025-05-05T19:37:44.494966Z",
     "shell.execute_reply": "2025-05-05T19:37:44.494747Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e201509a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:37:44.496111Z",
     "iopub.status.busy": "2025-05-05T19:37:44.496037Z",
     "iopub.status.idle": "2025-05-05T19:37:44.499234Z",
     "shell.execute_reply": "2025-05-05T19:37:44.499017Z"
    }
   },
   "outputs": [],
   "source": [
    "COMBINE_harmonizer.init(f'{root_dir}/config.yaml')\n",
    "\n",
    "out_dir = f\"{cfg.config['out_dir']}/out-publish-normalized\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75311ec",
   "metadata": {},
   "source": [
    "## 02. variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8c7f3e-c869-4eea-a9e8-59f50fdee5d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:37:44.500514Z",
     "iopub.status.busy": "2025-05-05T19:37:44.500441Z",
     "iopub.status.idle": "2025-05-05T19:37:44.501921Z",
     "shell.execute_reply": "2025-05-05T19:37:44.501704Z"
    }
   },
   "outputs": [],
   "source": [
    "filename_infos = COMBINE_harmonizer.FILENAME_INFOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78786538",
   "metadata": {},
   "source": [
    "## 03. Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f86f7-8644-42f9-9908-08b1c863afa3",
   "metadata": {},
   "source": [
    "### 03-3. process filename info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08e65e5-8569-4609-bf5d-170222a54303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:37:44.503124Z",
     "iopub.status.busy": "2025-05-05T19:37:44.503052Z",
     "iopub.status.idle": "2025-05-05T19:37:44.505274Z",
     "shell.execute_reply": "2025-05-05T19:37:44.505062Z"
    }
   },
   "outputs": [],
   "source": [
    "def _process_filename_info(filename_info):\n",
    "    # 1. read df\n",
    "    filename = filename_info['name']\n",
    "    full_filename = os.sep.join([out_dir, filename])\n",
    "    df =  pd.read_csv(full_filename, dtype='O')\n",
    "    df = df.fillna('')\n",
    "    valid_columns = list(filter(lambda column: not column.endswith('.orig'), df.columns))\n",
    "    df = df[valid_columns]\n",
    "\n",
    "    # 2. prefix.\n",
    "    prefix = COMBINE_harmonizer.flatten_filename_prefix(filename)\n",
    "    print(f'[INFO] _process_filename_info: filename: {filename} prefix: {prefix}')\n",
    "\n",
    "    if COMBINE_harmonizer.FLATTEN_INDEX not in df:\n",
    "        # 4. with prefix\n",
    "        df_with_prefix = COMBINE_harmonizer.flatten_columns_with_prefix(df.copy(), prefix)\n",
    "\n",
    "        return df, df_with_prefix\n",
    "\n",
    "    # 3. flatten.\n",
    "    df_flatten = COMBINE_harmonizer.flatten(df)\n",
    "\n",
    "    # 4. with prefix.\n",
    "    df_flatten_with_prefix = COMBINE_harmonizer.flatten_columns_with_prefix(df_flatten, prefix)\n",
    "\n",
    "    return df, df_flatten_with_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20a7049",
   "metadata": {},
   "source": [
    "## 04. Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a024f1c-d1cb-467e-a2ce-cd681143760b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T19:37:44.506429Z",
     "iopub.status.busy": "2025-05-05T19:37:44.506356Z",
     "iopub.status.idle": "2025-05-05T19:38:26.185616Z",
     "shell.execute_reply": "2025-05-05T19:38:26.182139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2/73) filename: 01-02-screening.csv name: 01-02 sheet_name: 01-02-screening\n",
      "[INFO] _process_filename_info: filename: 01-02-screening.csv prefix: 01-02\n",
      "(2/73) to df.excel\n",
      "(2/73) after df.excel\n",
      "(2/73) to merge\n",
      "(2/73) after merge: groupby: 532 is_invalid: 0\n",
      "(3/73) filename: 01-03-maternal-demographics.csv name: 01-03 sheet_name: 01-03-maternal-demographics\n",
      "[INFO] _process_filename_info: filename: 01-03-maternal-demographics.csv prefix: 01-03\n",
      "(3/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3/73) after df.excel\n",
      "(3/73) to merge\n",
      "(3/73) after merge: groupby: 532 is_invalid: 0\n",
      "(4/73) filename: 01-04-pregnancy-history.csv name: 01-04 sheet_name: 01-04-pregnancy-history\n",
      "[INFO] _process_filename_info: filename: 01-04-pregnancy-history.csv prefix: 01-04\n",
      "(4/73) to df.excel\n",
      "(4/73) after df.excel\n",
      "(4/73) to merge\n",
      "(4/73) after merge: groupby: 532 is_invalid: 0\n",
      "(5/73) filename: 01-05-labor-delivery.csv name: 01-05 sheet_name: 01-05-labor-delivery\n",
      "[INFO] _process_filename_info: filename: 01-05-labor-delivery.csv prefix: 01-05\n",
      "(5/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5/73) after df.excel\n",
      "(5/73) to merge\n",
      "(5/73) after merge: groupby: 532 is_invalid: 0\n",
      "(6/73) filename: 01-05_1-pse.csv name: 01-05_1 sheet_name: 01-05_1-pse\n",
      "[INFO] _process_filename_info: filename: 01-05_1-pse.csv prefix: 01-05_1\n",
      "(6/73) to df.excel\n",
      "(6/73) after df.excel\n",
      "(6/73) to merge\n",
      "(6/73) after merge: groupby: 532 is_invalid: 0\n",
      "(7/73) filename: 01-05_2-emergency-csection.csv name: 01-05_2 sheet_name: 01-05_2-emergency-csection\n",
      "[INFO] _process_filename_info: filename: 01-05_2-emergency-csection.csv prefix: 01-05_2\n",
      "(7/73) to df.excel\n",
      "(7/73) after df.excel\n",
      "(7/73) to merge\n",
      "(7/73) after merge: groupby: 532 is_invalid: 0\n",
      "(8/73) filename: 01-06-birth.csv name: 01-06 sheet_name: 01-06-birth\n",
      "[INFO] _process_filename_info: filename: 01-06-birth.csv prefix: 01-06\n",
      "(8/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8/73) after df.excel\n",
      "(8/73) to merge\n",
      "(8/73) after merge: groupby: 532 is_invalid: 0\n",
      "(9/73) filename: 01-07-pre-temperature.csv name: 01-07 sheet_name: 01-07-pre-temperature\n",
      "[INFO] _process_filename_info: filename: 01-07-pre-temperature.csv prefix: 01-07\n",
      "(9/73) to df.excel\n",
      "(9/73) after df.excel\n",
      "(9/73) to merge\n",
      "(9/73) after merge: groupby: 532 is_invalid: 0\n",
      "(10/73) filename: 01-08-pre-cardiovascular.csv name: 01-08 sheet_name: 01-08-pre-cardiovascular\n",
      "[INFO] _process_filename_info: filename: 01-08-pre-cardiovascular.csv prefix: 01-08\n",
      "(10/73) to df.excel\n",
      "(10/73) after df.excel\n",
      "(10/73) to merge\n",
      "(10/73) after merge: groupby: 532 is_invalid: 0\n",
      "(11/73) filename: 01-09-pre-infection.csv name: 01-09 sheet_name: 01-09-pre-infection\n",
      "[INFO] _process_filename_info: filename: 01-09-pre-infection.csv prefix: 01-09\n",
      "(11/73) to df.excel\n",
      "(11/73) after df.excel\n",
      "(11/73) to merge\n",
      "(11/73) after merge: groupby: 532 is_invalid: 0\n",
      "(12/73) filename: 01-10-pre-other-med.csv name: 01-10 sheet_name: 01-10-pre-other-med\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] _process_filename_info: filename: 01-10-pre-other-med.csv prefix: 01-10\n",
      "(12/73) to df.excel\n",
      "(12/73) after df.excel\n",
      "(12/73) to merge\n",
      "(12/73) after merge: groupby: 532 is_invalid: 0\n",
      "(13/73) filename: 01-11-pre-imaging.csv name: 01-11 sheet_name: 01-11-pre-imaging\n",
      "[INFO] _process_filename_info: filename: 01-11-pre-imaging.csv prefix: 01-11\n",
      "(13/73) to df.excel\n",
      "(13/73) after df.excel\n",
      "(13/73) to merge\n",
      "(13/73) after merge: groupby: 532 is_invalid: 0\n",
      "(14/73) filename: 01-12-neuro-exam.csv name: 01-12 sheet_name: 01-12-neuro-exam\n",
      "[INFO] _process_filename_info: filename: 01-12-neuro-exam.csv prefix: 01-12\n",
      "(14/73) to df.excel\n",
      "(14/73) after df.excel\n",
      "(14/73) to merge\n",
      "(14/73) after merge: groupby: 532 is_invalid: 0\n",
      "(15/73) filename: 01-12_1-total-modified-sarnat.csv name: 01-12_1 sheet_name: 01-12_1-total-modified-sarnat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] _process_filename_info: filename: 01-12_1-total-modified-sarnat.csv prefix: 01-12_1\n",
      "(15/73) to df.excel\n",
      "(15/73) after df.excel\n",
      "(15/73) to merge\n",
      "(15/73) after merge: groupby: 532 is_invalid: 0\n",
      "(16/73) filename: 02-01-temperature.csv name: 02-01 sheet_name: 02-01-temperature\n",
      "[INFO] _process_filename_info: filename: 02-01-temperature.csv prefix: 02-01\n",
      "_flatten: to pivot_table: df: 24439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: after pivot_table: time: 5.022918939590454\n",
      "_flatten: after to_flat_index\n",
      "(16/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16/73) after df.excel\n",
      "(16/73) to merge\n",
      "(16/73) after merge: groupby: 532 is_invalid: 0\n",
      "(17/73) filename: 02-02-cardiovascular.csv name: 02-02 sheet_name: 02-02-cardiovascular\n",
      "[INFO] _process_filename_info: filename: 02-02-cardiovascular.csv prefix: 02-02\n",
      "_flatten: to pivot_table: df: 13629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: after pivot_table: time: 2.546643018722534\n",
      "_flatten: after to_flat_index\n",
      "(17/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17/73) after df.excel\n",
      "(17/73) to merge\n",
      "(17/73) after merge: groupby: 532 is_invalid: 0\n",
      "(18/73) filename: 02-03-respiratory.csv name: 02-03 sheet_name: 02-03-respiratory\n",
      "[INFO] _process_filename_info: filename: 02-03-respiratory.csv prefix: 02-03\n",
      "_flatten: to pivot_table: df: 2794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: after pivot_table: time: 0.4752528667449951\n",
      "_flatten: after to_flat_index\n",
      "(18/73) to df.excel\n",
      "(18/73) after df.excel\n",
      "(18/73) to merge\n",
      "(18/73) after merge: groupby: 532 is_invalid: 0\n",
      "(19/73) filename: 02-04-blood-gas.csv name: 02-04 sheet_name: 02-04-blood-gas\n",
      "[INFO] _process_filename_info: filename: 02-04-blood-gas.csv prefix: 02-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: to pivot_table: df: 10768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: after pivot_table: time: 2.8145458698272705\n",
      "_flatten: after to_flat_index\n",
      "(19/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19/73) after df.excel\n",
      "(19/73) to merge\n",
      "(19/73) after merge: groupby: 532 is_invalid: 0\n",
      "(20/73) filename: 02-05-hematology.csv name: 02-05 sheet_name: 02-05-hematology\n",
      "[INFO] _process_filename_info: filename: 02-05-hematology.csv prefix: 02-05\n",
      "_flatten: to pivot_table: df: 2742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: after pivot_table: time: 0.618013858795166\n",
      "_flatten: after to_flat_index\n",
      "(20/73) to df.excel\n",
      "(20/73) after df.excel\n",
      "(20/73) to merge\n",
      "(20/73) after merge: groupby: 532 is_invalid: 0\n",
      "(21/73) filename: 02-05_s-hematology.csv name: 02-05_s sheet_name: 02-05_s-hematology\n",
      "[INFO] _process_filename_info: filename: 02-05_s-hematology.csv prefix: 02-05_s\n",
      "(21/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21/73) after df.excel\n",
      "(21/73) to merge\n",
      "(21/73) after merge: groupby: 532 is_invalid: 0\n",
      "(22/73) filename: 02-06_s-blood-value.csv name: 02-06_s sheet_name: 02-06_s-blood-value\n",
      "[INFO] _process_filename_info: filename: 02-06_s-blood-value.csv prefix: 02-06_s\n",
      "(22/73) to df.excel\n",
      "(22/73) after df.excel\n",
      "(22/73) to merge\n",
      "(22/73) after merge: groupby: 532 is_invalid: 0\n",
      "(23/73) filename: 02-07-infection.csv name: 02-07 sheet_name: 02-07-infection\n",
      "[INFO] _process_filename_info: filename: 02-07-infection.csv prefix: 02-07\n",
      "_flatten: to pivot_table: df: 532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: after pivot_table: time: 0.16095900535583496\n",
      "_flatten: after to_flat_index\n",
      "(23/73) to df.excel\n",
      "(23/73) after df.excel\n",
      "(23/73) to merge\n",
      "(23/73) after merge: groupby: 532 is_invalid: 0\n",
      "(24/73) filename: 02-08-other-med.csv name: 02-08 sheet_name: 02-08-other-med\n",
      "[INFO] _process_filename_info: filename: 02-08-other-med.csv prefix: 02-08\n",
      "_flatten: to pivot_table: df: 2757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: after pivot_table: time: 1.0844767093658447\n",
      "_flatten: after to_flat_index\n",
      "(24/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24/73) after df.excel\n",
      "(24/73) to merge\n",
      "(24/73) after merge: groupby: 532 is_invalid: 0\n",
      "(25/73) filename: 02-09-imaging.csv name: 02-09 sheet_name: 02-09-imaging\n",
      "[INFO] _process_filename_info: filename: 02-09-imaging.csv prefix: 02-09\n",
      "_flatten: to pivot_table: df: 525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: after pivot_table: time: 0.36553001403808594\n",
      "_flatten: after to_flat_index\n",
      "(25/73) to df.excel\n",
      "(25/73) after df.excel\n",
      "(25/73) to merge\n",
      "(25/73) after merge: groupby: 532 is_invalid: 0\n",
      "(26/73) filename: 02-11-elevated-temperature.csv name: 02-11 sheet_name: 02-11-elevated-temperature\n",
      "[INFO] _process_filename_info: filename: 02-11-elevated-temperature.csv prefix: 02-11\n",
      "_flatten: to pivot_table: df: 445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: after pivot_table: time: 0.12133193016052246\n",
      "_flatten: after to_flat_index\n",
      "(26/73) to df.excel\n",
      "(26/73) after df.excel\n",
      "(26/73) to merge\n",
      "(26/73) after merge: groupby: 532 is_invalid: 0\n",
      "(27/73) filename: 02-12-fluctuated-temperature.csv name: 02-12 sheet_name: 02-12-fluctuated-temperature\n",
      "[INFO] _process_filename_info: filename: 02-12-fluctuated-temperature.csv prefix: 02-12\n",
      "_flatten: to pivot_table: df: 54\n",
      "_flatten: after pivot_table: time: 0.01747608184814453\n",
      "_flatten: after to_flat_index\n",
      "(27/73) to df.excel\n",
      "(27/73) after df.excel\n",
      "(27/73) to merge\n",
      "(27/73) after merge: groupby: 532 is_invalid: 0\n",
      "(28/73) filename: 02-13-bradycardia.csv name: 02-13 sheet_name: 02-13-bradycardia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] _process_filename_info: filename: 02-13-bradycardia.csv prefix: 02-13\n",
      "_flatten: to pivot_table: df: 210\n",
      "_flatten: after pivot_table: time: 0.05103588104248047\n",
      "_flatten: after to_flat_index\n",
      "(28/73) to df.excel\n",
      "(28/73) after df.excel\n",
      "(28/73) to merge\n",
      "(28/73) after merge: groupby: 532 is_invalid: 0\n",
      "(29/73) filename: 02-14-adverse-event.csv name: 02-14 sheet_name: 02-14-adverse-event\n",
      "[INFO] _process_filename_info: filename: 02-14-adverse-event.csv prefix: 02-14\n",
      "_flatten: to pivot_table: df: 111\n",
      "_flatten: after pivot_table: time: 0.11652302742004395\n",
      "_flatten: after to_flat_index\n",
      "(29/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29/73) after df.excel\n",
      "(29/73) to merge\n",
      "(29/73) after merge: groupby: 532 is_invalid: 0\n",
      "(30/73) filename: 02-15-violation.csv name: 02-15 sheet_name: 02-15-violation\n",
      "[INFO] _process_filename_info: filename: 02-15-violation.csv prefix: 02-15\n",
      "_flatten: to pivot_table: df: 156\n",
      "_flatten: after pivot_table: time: 0.02857804298400879\n",
      "_flatten: after to_flat_index\n",
      "(30/73) to df.excel\n",
      "(30/73) after df.excel\n",
      "(30/73) to merge\n",
      "(30/73) after merge: groupby: 532 is_invalid: 0\n",
      "(31/73) filename: 02-16-interrupt.csv name: 02-16 sheet_name: 02-16-interrupt\n",
      "[INFO] _process_filename_info: filename: 02-16-interrupt.csv prefix: 02-16\n",
      "_flatten: to pivot_table: df: 249\n",
      "_flatten: after pivot_table: time: 0.04368114471435547\n",
      "_flatten: after to_flat_index\n",
      "(31/73) to df.excel\n",
      "(31/73) after df.excel\n",
      "(31/73) to merge\n",
      "(31/73) after merge: groupby: 532 is_invalid: 0\n",
      "(32/73) filename: 02-17-discontinue.csv name: 02-17 sheet_name: 02-17-discontinue\n",
      "[INFO] _process_filename_info: filename: 02-17-discontinue.csv prefix: 02-17\n",
      "(32/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32/73) after df.excel\n",
      "(32/73) to merge\n",
      "(32/73) after merge: groupby: 532 is_invalid: 0\n",
      "(33/73) filename: 03-01-post-temperature.csv name: 03-01 sheet_name: 03-01-post-temperature\n",
      "[INFO] _process_filename_info: filename: 03-01-post-temperature.csv prefix: 03-01\n",
      "_flatten: to pivot_table: df: 2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: after pivot_table: time: 0.3100399971008301\n",
      "_flatten: after to_flat_index\n",
      "(33/73) to df.excel\n",
      "(33/73) after df.excel\n",
      "(33/73) to merge\n",
      "(33/73) after merge: groupby: 532 is_invalid: 0\n",
      "(34/73) filename: 03-01_s-post-temperature.csv name: 03-01_s sheet_name: 03-01_s-post-temperature\n",
      "[INFO] _process_filename_info: filename: 03-01_s-post-temperature.csv prefix: 03-01_s\n",
      "(34/73) to df.excel\n",
      "(34/73) after df.excel\n",
      "(34/73) to merge\n",
      "(34/73) after merge: groupby: 532 is_invalid: 0\n",
      "(35/73) filename: 03-02-post-blood-value.csv name: 03-02 sheet_name: 03-02-post-blood-value\n",
      "[INFO] _process_filename_info: filename: 03-02-post-blood-value.csv prefix: 03-02\n",
      "(35/73) to df.excel\n",
      "(35/73) after df.excel\n",
      "(35/73) to merge\n",
      "(35/73) after merge: groupby: 532 is_invalid: 0\n",
      "(36/73) filename: 03-03-post-imaging.csv name: 03-03 sheet_name: 03-03-post-imaging\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] _process_filename_info: filename: 03-03-post-imaging.csv prefix: 03-03\n",
      "(36/73) to df.excel\n",
      "(36/73) after df.excel\n",
      "(36/73) to merge\n",
      "(36/73) after merge: groupby: 532 is_invalid: 0\n",
      "(37/73) filename: 03-04-post-neuro-exam.csv name: 03-04 sheet_name: 03-04-post-neuro-exam\n",
      "[INFO] _process_filename_info: filename: 03-04-post-neuro-exam.csv prefix: 03-04\n",
      "(37/73) to df.excel\n",
      "(37/73) after df.excel\n",
      "(37/73) to merge\n",
      "(37/73) after merge: groupby: 532 is_invalid: 0\n",
      "(38/73) filename: 03-04_1-total-modified-sarnat.csv name: 03-04_1 sheet_name: 03-04_1-total-modified-sarnat\n",
      "[INFO] _process_filename_info: filename: 03-04_1-total-modified-sarnat.csv prefix: 03-04_1\n",
      "(38/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38/73) after df.excel\n",
      "(38/73) to merge\n",
      "(38/73) after merge: groupby: 532 is_invalid: 0\n",
      "(39/73) filename: 03-05-mri.csv name: 03-05 sheet_name: 03-05-mri\n",
      "[INFO] _process_filename_info: filename: 03-05-mri.csv prefix: 03-05\n",
      "_flatten: to pivot_table: df: 915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_flatten: after pivot_table: time: 1.8213942050933838\n",
      "_flatten: after to_flat_index\n",
      "(39/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39/73) after df.excel\n",
      "(39/73) to merge\n",
      "(39/73) after merge: groupby: 532 is_invalid: 0\n",
      "(40/73) filename: 03-05_s-mri.csv name: 03-05_s sheet_name: 03-05_s-mri\n",
      "[INFO] _process_filename_info: filename: 03-05_s-mri.csv prefix: 03-05_s\n",
      "(40/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40/73) after df.excel\n",
      "(40/73) to merge\n",
      "(40/73) after merge: groupby: 532 is_invalid: 0\n",
      "(41/73) filename: 03-05_s1-mri.csv name: 03-05_s1 sheet_name: 03-05_s1-mri\n",
      "[INFO] _process_filename_info: filename: 03-05_s1-mri.csv prefix: 03-05_s1\n",
      "(41/73) to df.excel\n",
      "(41/73) after df.excel\n",
      "(41/73) to merge\n",
      "(41/73) after merge: groupby: 532 is_invalid: 0\n",
      "(42/73) filename: 04-01-status.csv name: 04-01 sheet_name: 04-01-status\n",
      "[INFO] _process_filename_info: filename: 04-01-status.csv prefix: 04-01\n",
      "(42/73) to df.excel\n",
      "(42/73) after df.excel\n",
      "(42/73) to merge\n",
      "(42/73) after merge: groupby: 532 is_invalid: 0\n",
      "(43/73) filename: 04-01_1-length-of-stay.csv name: 04-01_1 sheet_name: 04-01_1-length-of-stay\n",
      "[INFO] _process_filename_info: filename: 04-01_1-length-of-stay.csv prefix: 04-01_1\n",
      "(43/73) to df.excel\n",
      "(43/73) after df.excel\n",
      "(43/73) to merge\n",
      "(43/73) after merge: groupby: 532 is_invalid: 0\n",
      "(44/73) filename: 04-02-cardiovascular.csv name: 04-02 sheet_name: 04-02-cardiovascular\n",
      "[INFO] _process_filename_info: filename: 04-02-cardiovascular.csv prefix: 04-02\n",
      "(44/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44/73) after df.excel\n",
      "(44/73) to merge\n",
      "(44/73) after merge: groupby: 532 is_invalid: 0\n",
      "(45/73) filename: 04-03-respiratory.csv name: 04-03 sheet_name: 04-03-respiratory\n",
      "[INFO] _process_filename_info: filename: 04-03-respiratory.csv prefix: 04-03\n",
      "(45/73) to df.excel\n",
      "(45/73) after df.excel\n",
      "(45/73) to merge\n",
      "(45/73) after merge: groupby: 532 is_invalid: 0\n",
      "(46/73) filename: 04-04-hematology.csv name: 04-04 sheet_name: 04-04-hematology\n",
      "[INFO] _process_filename_info: filename: 04-04-hematology.csv prefix: 04-04\n",
      "(46/73) to df.excel\n",
      "(46/73) after df.excel\n",
      "(46/73) to merge\n",
      "(46/73) after merge: groupby: 532 is_invalid: 0\n",
      "(47/73) filename: 04-05-metabolic.csv name: 04-05 sheet_name: 04-05-metabolic\n",
      "[INFO] _process_filename_info: filename: 04-05-metabolic.csv prefix: 04-05\n",
      "(47/73) to df.excel\n",
      "(47/73) after df.excel\n",
      "(47/73) to merge\n",
      "(47/73) after merge: groupby: 532 is_invalid: 0\n",
      "(48/73) filename: 04-06-renal.csv name: 04-06 sheet_name: 04-06-renal\n",
      "[INFO] _process_filename_info: filename: 04-06-renal.csv prefix: 04-06\n",
      "(48/73) to df.excel\n",
      "(48/73) after df.excel\n",
      "(48/73) to merge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48/73) after merge: groupby: 532 is_invalid: 0\n",
      "(49/73) filename: 04-07-gastrointestinal.csv name: 04-07 sheet_name: 04-07-gastrointestinal\n",
      "[INFO] _process_filename_info: filename: 04-07-gastrointestinal.csv prefix: 04-07\n",
      "(49/73) to df.excel\n",
      "(49/73) after df.excel\n",
      "(49/73) to merge\n",
      "(49/73) after merge: groupby: 532 is_invalid: 0\n",
      "(50/73) filename: 04-08-skin.csv name: 04-08 sheet_name: 04-08-skin\n",
      "[INFO] _process_filename_info: filename: 04-08-skin.csv prefix: 04-08\n",
      "(50/73) to df.excel\n",
      "(50/73) after df.excel\n",
      "(50/73) to merge\n",
      "(50/73) after merge: groupby: 532 is_invalid: 0\n",
      "(51/73) filename: 04-09-auditory.csv name: 04-09 sheet_name: 04-09-auditory\n",
      "[INFO] _process_filename_info: filename: 04-09-auditory.csv prefix: 04-09\n",
      "(51/73) to df.excel\n",
      "(51/73) after df.excel\n",
      "(51/73) to merge\n",
      "(51/73) after merge: groupby: 532 is_invalid: 0\n",
      "(52/73) filename: 04-10-surgery.csv name: 04-10 sheet_name: 04-10-surgery\n",
      "[INFO] _process_filename_info: filename: 04-10-surgery.csv prefix: 04-10\n",
      "(52/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52/73) after df.excel\n",
      "(52/73) to merge\n",
      "(52/73) after merge: groupby: 532 is_invalid: 0\n",
      "(53/73) filename: 04-11-infection.csv name: 04-11 sheet_name: 04-11-infection\n",
      "[INFO] _process_filename_info: filename: 04-11-infection.csv prefix: 04-11\n",
      "(53/73) to df.excel\n",
      "(53/73) after df.excel\n",
      "(53/73) to merge\n",
      "(53/73) after merge: groupby: 532 is_invalid: 0\n",
      "(54/73) filename: 04-12-neuro-exam.csv name: 04-12 sheet_name: 04-12-neuro-exam\n",
      "[INFO] _process_filename_info: filename: 04-12-neuro-exam.csv prefix: 04-12\n",
      "(54/73) to df.excel\n",
      "(54/73) after df.excel\n",
      "(54/73) to merge\n",
      "(54/73) after merge: groupby: 532 is_invalid: 0\n",
      "(55/73) filename: 04-12_1-total-modified-sarnat.csv name: 04-12_1 sheet_name: 04-12_1-total-modified-sarnat\n",
      "[INFO] _process_filename_info: filename: 04-12_1-total-modified-sarnat.csv prefix: 04-12_1\n",
      "(55/73) to df.excel\n",
      "(55/73) after df.excel\n",
      "(55/73) to merge\n",
      "(55/73) after merge: groupby: 532 is_invalid: 0\n",
      "(56/73) filename: 04-13-seizure.csv name: 04-13 sheet_name: 04-13-seizure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] _process_filename_info: filename: 04-13-seizure.csv prefix: 04-13\n",
      "(56/73) to df.excel\n",
      "(56/73) after df.excel\n",
      "(56/73) to merge\n",
      "(56/73) after merge: groupby: 532 is_invalid: 0\n",
      "(57/73) filename: 04-14-birth-defect.csv name: 04-14 sheet_name: 04-14-birth-defect\n",
      "[INFO] _process_filename_info: filename: 04-14-birth-defect.csv prefix: 04-14\n",
      "(57/73) to df.excel\n",
      "(57/73) after df.excel\n",
      "(57/73) to merge\n",
      "(57/73) after merge: groupby: 532 is_invalid: 0\n",
      "(58/73) filename: 04-15-home-therapy.csv name: 04-15 sheet_name: 04-15-home-therapy\n",
      "[INFO] _process_filename_info: filename: 04-15-home-therapy.csv prefix: 04-15\n",
      "(58/73) to df.excel\n",
      "(58/73) after df.excel\n",
      "(58/73) to merge\n",
      "(58/73) after merge: groupby: 532 is_invalid: 0\n",
      "(59/73) filename: 04-16-wdraw-support.csv name: 04-16 sheet_name: 04-16-wdraw-support\n",
      "[INFO] _process_filename_info: filename: 04-16-wdraw-support.csv prefix: 04-16\n",
      "(59/73) to df.excel\n",
      "(59/73) after df.excel\n",
      "(59/73) to merge\n",
      "(59/73) after merge: groupby: 532 is_invalid: 0\n",
      "(60/73) filename: 04-17-limit-care.csv name: 04-17 sheet_name: 04-17-limit-care\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] _process_filename_info: filename: 04-17-limit-care.csv prefix: 04-17\n",
      "(60/73) to df.excel\n",
      "(60/73) after df.excel\n",
      "(60/73) to merge\n",
      "(60/73) after merge: groupby: 532 is_invalid: 0\n",
      "(61/73) filename: 20-00-follow-up.csv name: 20-00 sheet_name: 20-00-follow-up\n",
      "[INFO] _process_filename_info: filename: 20-00-follow-up.csv prefix: 20-00\n",
      "(61/73) to df.excel\n",
      "(61/73) after df.excel\n",
      "(61/73) to merge\n",
      "(61/73) after merge: groupby: 532 is_invalid: 0\n",
      "(62/73) filename: 20-01-ses.csv name: 20-01 sheet_name: 20-01-ses\n",
      "[INFO] _process_filename_info: filename: 20-01-ses.csv prefix: 20-01\n",
      "(62/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62/73) after df.excel\n",
      "(62/73) to merge\n",
      "(62/73) after merge: groupby: 532 is_invalid: 0\n",
      "(63/73) filename: 20-02-medical-history.csv name: 20-02 sheet_name: 20-02-medical-history\n",
      "[INFO] _process_filename_info: filename: 20-02-medical-history.csv prefix: 20-02\n",
      "(63/73) to df.excel\n",
      "(63/73) after df.excel\n",
      "(63/73) to merge\n",
      "(63/73) after merge: groupby: 532 is_invalid: 0\n",
      "(64/73) filename: 20-03-medical-exam.csv name: 20-03 sheet_name: 20-03-medical-exam\n",
      "[INFO] _process_filename_info: filename: 20-03-medical-exam.csv prefix: 20-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64/73) to df.excel\n",
      "(64/73) after df.excel\n",
      "(64/73) to merge\n",
      "(64/73) after merge: groupby: 532 is_invalid: 0\n",
      "(65/73) filename: 20-04-bayley-iii.csv name: 20-04 sheet_name: 20-04-bayley-iii\n",
      "[INFO] _process_filename_info: filename: 20-04-bayley-iii.csv prefix: 20-04\n",
      "(65/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65/73) after df.excel\n",
      "(65/73) to merge\n",
      "(65/73) after merge: groupby: 532 is_invalid: 0\n",
      "(66/73) filename: 20-05-gmfcs.csv name: 20-05 sheet_name: 20-05-gmfcs\n",
      "[INFO] _process_filename_info: filename: 20-05-gmfcs.csv prefix: 20-05\n",
      "(66/73) to df.excel\n",
      "(66/73) after df.excel\n",
      "(66/73) to merge\n",
      "(66/73) after merge: groupby: 532 is_invalid: 0\n",
      "(67/73) filename: 20-06-status.csv name: 20-06 sheet_name: 20-06-status\n",
      "[INFO] _process_filename_info: filename: 20-06-status.csv prefix: 20-06\n",
      "(67/73) to df.excel\n",
      "(67/73) after df.excel\n",
      "(67/73) to merge\n",
      "(67/73) after merge: groupby: 532 is_invalid: 0\n",
      "(68/73) filename: 20-07-readmission.csv name: 20-07 sheet_name: 20-07-readmission\n",
      "[INFO] _process_filename_info: filename: 20-07-readmission.csv prefix: 20-07\n",
      "_flatten: to pivot_table: df: 212\n",
      "_flatten: after pivot_table: time: 0.031213760375976562\n",
      "_flatten: after to_flat_index\n",
      "(68/73) to df.excel\n",
      "(68/73) after df.excel\n",
      "(68/73) to merge\n",
      "(68/73) after merge: groupby: 532 is_invalid: 0\n",
      "(69/73) filename: 20-08-lost.csv name: 20-08 sheet_name: 20-08-lost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] _process_filename_info: filename: 20-08-lost.csv prefix: 20-08\n",
      "(69/73) to df.excel\n",
      "(69/73) after df.excel\n",
      "(69/73) to merge\n",
      "(69/73) after merge: groupby: 532 is_invalid: 0\n",
      "(70/73) filename: 20-09-secondary.csv name: 20-09 sheet_name: 20-09-secondary\n",
      "[INFO] _process_filename_info: filename: 20-09-secondary.csv prefix: 20-09\n",
      "(70/73) to df.excel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70/73) after df.excel\n",
      "(70/73) to merge\n",
      "(70/73) after merge: groupby: 532 is_invalid: 0\n",
      "(71/73) filename: 20-10-outcome.csv name: 20-10 sheet_name: 20-10-outcome\n",
      "[INFO] _process_filename_info: filename: 20-10-outcome.csv prefix: 20-10\n",
      "(71/73) to df.excel\n",
      "(71/73) after df.excel\n",
      "(71/73) to merge\n",
      "(71/73) after merge: groupby: 532 is_invalid: 0\n",
      "(72/73) filename: 20-10_1-disability-level-death.csv name: 20-10_1 sheet_name: 20-10_1-disability-level-death\n",
      "[INFO] _process_filename_info: filename: 20-10_1-disability-level-death.csv prefix: 20-10_1\n",
      "(72/73) to df.excel\n",
      "(72/73) after df.excel\n",
      "(72/73) to merge\n",
      "(72/73) after merge: groupby: 532 is_invalid: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged columns: 6119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to excel.close\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "out_filename = os.sep.join([out_dir, 'zz-merged.xlsx'])\n",
    "excel = pd.ExcelWriter(out_filename, engine='xlsxwriter')\n",
    "\n",
    "df_merge = None\n",
    "for idx, filename_info in enumerate(filename_infos):\n",
    "    if not filename_info.get('is_merge', True):\n",
    "        continue\n",
    "\n",
    "    # 1. names\n",
    "    filename = filename_info['name']\n",
    "    prefix = COMBINE_harmonizer.flatten_filename_prefix(filename)\n",
    "    sheet_name = COMBINE_harmonizer.flatten_sheet_name(filename)\n",
    "    print(f\"({idx}/{len(filename_infos)}) filename: {filename_info['name']} name: {prefix} sheet_name: {sheet_name}\")\n",
    "\n",
    "    # 2. process file info.\n",
    "    # df for sheet in excel.\n",
    "    # df_flatten for merging as the flattened csv.\n",
    "    df, df_flatten = _process_filename_info(filename_info)\n",
    "\n",
    "    # 3. to excel.\n",
    "    print(f'({idx}/{len(filename_infos)}) to df.excel')\n",
    "    df.to_excel(excel, sheet_name=sheet_name)\n",
    "    print(f'({idx}/{len(filename_infos)}) after df.excel')\n",
    "\n",
    "    # 4. to merge.\n",
    "    print(f'({idx}/{len(filename_infos)}) to merge')\n",
    "    if df_merge is None:\n",
    "        df_merge = df_flatten\n",
    "    else:\n",
    "        df_merge = df_merge.merge(df_flatten, on=COMBINE_harmonizer.FLATTEN_MERGE_COLUMNS, how='outer')\n",
    "\n",
    "    # 5. check that unique-id is still unique.\n",
    "    df_groupby = df_merge.groupby(COMBINE_harmonizer.FLATTEN_MERGE_COLUMNS).agg(count=('_study', 'count'))\n",
    "    is_invalid = df_groupby['count'] > 1\n",
    "    print(f'({idx}/{len(filename_infos)}) after merge: groupby: {len(df_groupby)} is_invalid: {is_invalid.sum()}')\n",
    "\n",
    "# save to csv.\n",
    "out_filename = os.sep.join([out_dir, 'zz-merged-flatten.csv'])\n",
    "df_merge.to_csv(out_filename, index=False)\n",
    "\n",
    "# merge to excel.\n",
    "print(f'merged columns: {len(df_merge.columns)}')\n",
    "# df_merge = df_merge.transpose()\n",
    "df_merge.to_excel(excel, sheet_name='flatten')\n",
    "\n",
    "# close excel.\n",
    "print('to excel.close')\n",
    "excel.close()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf5536-4993-48a2-b363-963252c83863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
